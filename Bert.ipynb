{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment_Analysis_Bert.ipynb",
      "provenance": [],
      "mount_file_id": "12Qqq8oG_TR2-rnyYwD7ElW4vrMopvgCO",
      "authorship_tag": "ABX9TyPdWI3Ar5uVdHQW3UdEO7vq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikarraju/NLP_Project/blob/main/Sentiment_Analysis_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsScfwWbH82M"
      },
      "source": [
        "!pip3 install -q ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7OGaUHvMOw6"
      },
      "source": [
        "def get_sentence_labels(text):\n",
        "  tweets = []\n",
        "  labels = []\n",
        "  lines = text.splitlines()\n",
        "  for line in lines:\n",
        "    print(line)\n",
        "    words = line.split()\n",
        "    labels.append(words[1])\n",
        "    tweet_text = ''\n",
        "    for i in range(2,len(words)):\n",
        "      tweet_text += words[i]+' '\n",
        "    tweets.append(tweet_text)\n",
        "  return tweets,labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwcXAhDiPnv1"
      },
      "source": [
        "#replace all emojis with phrases\n",
        "import re\n",
        "def replace_emojis(text):\n",
        "  happyface = \":\\)\"\n",
        "  text = re.sub(r\"http.*\",\"url\",text)\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \":-\\)\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \":-\\]\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \":\\]\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \"=\\)\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \":\\'-\\)\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  happyface = \":\\'\\)\"\n",
        "  text = re.sub(happyface,\"happyface\",text)\n",
        "  sadface = \":\\(\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \":-\\(\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \":\\[\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \":-\\[\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \":\\'-\\(\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \":\\'\\(\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  sadface = \"\\(:\"\n",
        "  text = re.sub(sadface,\"sadface\",text)\n",
        "  # text = re.sub(\":|\",\"neutralface\",text)\n",
        "  text = re.sub(\":P\",\"lolface\",text)\n",
        "  text = re.sub(\":p\",\"lolface\",text)\n",
        "  text = re.sub(\":o\",\"surprise\",text)\n",
        "  text = re.sub(\":O\",\"surprise\",text)\n",
        "  #print(text[0:1000])\n",
        "  return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bacxxQnP3YK"
      },
      "source": [
        "import re\n",
        "def remove_punctuations(input_string):\n",
        "  input_string = re.sub(r'\\\\u002c','',input_string)\n",
        "  input_string = re.sub(r'@.*','',input_string)\n",
        "  input_string = re.sub(r'#.*',' ',input_string)\n",
        "  input_string = re.sub(r'[0-9]+', '', input_string)\n",
        "  res = re.sub(r'[^\\w\\s]', '', input_string)\n",
        "  return res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2tORRN5QMof"
      },
      "source": [
        "def remove_recurring_characters(sentences):\n",
        "  def remove_recurring_characters_in_word(word):\n",
        "    i = 1\n",
        "    rec_count = 0\n",
        "    while i < len(word):\n",
        "      if word[i] == word[i-1]:\n",
        "        rec_count += 1\n",
        "      else:\n",
        "        rec_count =0\n",
        "      if rec_count>=2:\n",
        "        word = word[:i]+word[i+1:]\n",
        "        i -= 1\n",
        "      i += 1\n",
        "    return word\n",
        "  for sent in sentences:\n",
        "    for i in range(len(sent)):\n",
        "      sent[i] = remove_recurring_characters_in_word(sent[i]).lower()\n",
        "  print(sentences[0:10])\n",
        "  return sentences"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF6MLsJgLO6U"
      },
      "source": [
        "train_file = open(\"/content/drive/MyDrive/Colab Notebooks/NLP/Project/datasets/train_2017\",'r',encoding='utf-8')\n",
        "text = train_file.read()\n",
        "train_file.close()\n",
        "\n",
        "text = replace_emojis(text)\n",
        "text = remove_punctuations(text)\n",
        "\n",
        "tweets,labels = get_sentence_labels2(text)\n",
        "\n",
        "train_cnt = int(0.75*len(tweets))\n",
        "train_x = tweets[0:train_cnt]\n",
        "train_y = labels[0:train_cnt]\n",
        "val_x = tweets[train_cnt:]\n",
        "val_y = labels[train_cnt:]\n",
        "\n",
        "class_names = ['positive','negative','neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whpgPz7QPgez"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, classes=class_names)\n",
        "trn = t.preprocess_train(train_x, train_y)\n",
        "val = t.preprocess_test(val_x, val_y)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6rqiM9WPlFf"
      },
      "source": [
        "learner.fit_onecycle(5e-5, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2WKtHMW72PA"
      },
      "source": [
        "def get_sentence_labels2(text):\n",
        "  tweets = []\n",
        "  labels = []\n",
        "  lines = text.splitlines()\n",
        "  for line in lines:\n",
        "    print(line)\n",
        "    words = line.split()\n",
        "    labels.append(words[0])\n",
        "    tweet_text = ''\n",
        "    for i in range(1,len(words)):\n",
        "      tweet_text += words[i]+' '\n",
        "    tweets.append(tweet_text)\n",
        "  return tweets,labels"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-zIAd4jiP6"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
        "\n",
        "\n",
        "test_file = open('/content/drive/MyDrive/Datasets/test_2016')\n",
        "text2 = test_file.read()\n",
        "test_file.close()\n",
        "\n",
        "tweets,labels = get_sentences_labels(text2)\n",
        "\n",
        "test_labels = []\n",
        "for line in tweets:\n",
        "  prediction = predictor.predict(line)\n",
        "  test_labels.append(prediction)\n",
        "#print(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EftpA9q3S39c"
      },
      "source": [
        "def calculate_avg_recall(predictions,test_y):\n",
        "  true_pos_predcited,total_true_pos = 0,0\n",
        "  true_neg_predcited,total_true_neg = 0,0\n",
        "  true_neu_predcited,total_true_neu = 0,0\n",
        "  for i in range(len(predictions)):\n",
        "    if test_y[i] == 2:\n",
        "      total_true_pos += 1\n",
        "      if predictions[i] == 2:\n",
        "        true_pos_predcited += 1\n",
        "    elif test_y[i] == 0:\n",
        "      total_true_neg += 1\n",
        "      if predictions[i] == 0:\n",
        "        true_neg_predcited += 1\n",
        "    elif test_y[i] == 1:\n",
        "      total_true_neu += 1\n",
        "      if predictions[i] == 1:\n",
        "        true_neu_predcited += 1\n",
        "  print(true_pos_predcited/total_true_pos,true_neg_predcited/total_true_neg,true_neu_predcited/total_true_neu)\n",
        "  print(sum([true_pos_predcited/total_true_pos,true_neg_predcited/total_true_neg,true_neu_predcited/total_true_neu])/3)\n",
        "  return sum([true_pos_predcited/total_true_pos,true_neg_predcited/total_true_neg,true_neu_predcited/total_true_neu])/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86UJcT5YNlhZ"
      },
      "source": [
        "label_dict = {'neutral':1,'negative':0,'positive':2}\n",
        "test_y,predictions = [],[]\n",
        "for i in range(len(labels)):\n",
        "  test_y.append(label_dict[labels[i]])\n",
        "  predictions.append(label_dict[test_labels[i]])\n",
        "calculate_avg_recall(predictions,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3eaFQ70astA"
      },
      "source": [
        "import pandas as pd\n",
        "output_df = pd.DataFrame({'predictions':predictions},index=None)\n",
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/NLP/Project/Results/BERT_2016.csv',index=False) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
